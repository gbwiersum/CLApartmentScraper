{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import random\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cyQnX9Xy1OnE",
    "outputId": "53cec896-68e2-4ade-866b-39619f1f2035"
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "import time\n",
    "import datetime\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TZd5PVQq8NeI"
   },
   "source": [
    "Defining basic methods,\n",
    "Building the scraping engine. \n",
    "\n",
    "\n",
    "1.   Gets each page of listings\n",
    "2.   For each page of listings, gets attributes and headline descriptions, sqft, rent and a url for the posting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "NtWJ5_vuwd0J"
   },
   "outputs": [],
   "source": [
    "# Open a browser instance.\n",
    "def start_browser(headless = True):\n",
    "    chrome_options = webdriver.ChromeOptions()\n",
    "    if headless:\n",
    "        chrome_options.add_argument('--headless')\n",
    "        chrome_options.add_argument('--no-sandbox')\n",
    "        chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "        webbrowser = webdriver.Chrome(\"chromedriver\", options=chrome_options)\n",
    "    if not headless:\n",
    "        webbrowser.set_window_size(48, 32)\n",
    "    return webbrowser\n",
    "\n",
    "\n",
    "#Generates a list of valid page urls from a given starting point.\n",
    "def get_pages(start_url, browser, results=-1, cooldown=1):\n",
    "    browser.get(start_url)\n",
    "    end = ''\n",
    "    while end=='':\n",
    "        soup = BeautifulSoup(browser.page_source)\n",
    "        end = soup.find('span', class_='cl-page-number').text\n",
    "\n",
    "    m = re.search(\"of \"+'(.+%?)',end)\n",
    "\n",
    "    if m is not None:\n",
    "        end = int(m.group(1).replace(\",\", \"\"))\n",
    "\n",
    "    if results !=-1:\n",
    "        end = min([end, results])\n",
    "\n",
    "    pages = end//120\n",
    "    pagelist = []\n",
    "    for n in range(0, pages):\n",
    "        pagelist.append((start_url+'#search=1~list~'+str(n)))\n",
    "\n",
    "    return pagelist\n",
    "\n",
    "def get_listings(pagelist, browser=start_browser()):\n",
    "    links = []\n",
    "    for p in pages:\n",
    "        browser.get(p)\n",
    "        while browser.page_source is None:\n",
    "            sleep(1)\n",
    "        source = BeautifulSoup(browser.page_source).ol.find_all('li')\n",
    "        for s in source:\n",
    "            links.append(s.a.get('href'))\n",
    "    return links\n",
    "\n",
    "#utility to pull variables out of xml data using leading and following tag.\n",
    "#I refusue to learn regex and this is my workaround for that.\n",
    "def xml_getter(text, before=\"\", after=\"\"):\n",
    "    if text is not None:\n",
    "        text = str(text)\n",
    "        m = re.search(before+'(.+?)'+after, text)\n",
    "        if m:\n",
    "            found = m.group(1).strip()\n",
    "            return(found)\n",
    "    else: return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Listing object holds all information relevant to the post. Non normalized, Has redundancy.\n",
    "\n",
    "class Listing:\n",
    "\n",
    "    def __init__(self, url, browser):\n",
    "        self.url = url\n",
    "        browser.get(url)\n",
    "        self.ID = xml_getter(url, before = \"/\", after=\".html\")[-10::]\n",
    "\n",
    "        try:\n",
    "            self.html = BeautifulSoup(browser.page_source)\n",
    "        except:\n",
    "            try:\n",
    "                time.sleep(1)\n",
    "                browser.get(url)\n",
    "                time.sleep(1)\n",
    "                self.html=BeautifulSoup(browser.page_source)\n",
    "            except:\n",
    "                pass\n",
    "\n",
    "            \n",
    "    def parse(self):\n",
    "\n",
    "        def get_price(self):\n",
    "            try:\n",
    "                price = self.html.find('span', class_='price').text\n",
    "                price = re.sub(r'[^\\d.]', '', str(price))\n",
    "                return(int(price))\n",
    "            except:\n",
    "                return(None)\n",
    "\n",
    "        def get_beds(self):\n",
    "            housing = self.html.find(\"span\", class_='housing')\n",
    "            if housing is not None:\n",
    "                beds = xml_getter(housing.text.lower(), before=' ', after=\"br\")\n",
    "            else:\n",
    "                beds = 0\n",
    "            return(beds)\n",
    "\n",
    "        def get_sqft(self):\n",
    "            housing = self.html.find('span', class_='housing')\n",
    "            if housing is not None:\n",
    "                sqft =xml_getter(housing.text.lower(), before=' - ', after=\"ft2\")\n",
    "                if sqft is not None:\n",
    "                    sqft = int(sqft)\n",
    "                else: sqft = None\n",
    "            else: sqft = None\n",
    "            return(sqft)\n",
    "\n",
    "        def get_park(self):\n",
    "            park = xml_getter(self.html, before='>', after=\"parking\")\n",
    "            return(park)\n",
    "\n",
    "        def get_baths(self):\n",
    "            bedbath = self.html.find('span', class_='shared-line-bubble')\n",
    "            if bedbath is not None:\n",
    "                baths = xml_getter(bedbath.text.lower(), before=\"/ \", after='ba')\n",
    "                return(baths)\n",
    "            else: return None\n",
    "\n",
    "        def get_body(self):\n",
    "            body = self.html.find('section', id='postingbody')\n",
    "            if body is not None:\n",
    "                body = body.text\n",
    "                body = body.replace(\"\\n\\nQR Code Link to This Post\\n\\n\\n\", \"\")\n",
    "                body = body.replace(\"\\n\", \" \")\n",
    "                return(body)\n",
    "            else: return \" \"\n",
    "\n",
    "        def get_address(self):\n",
    "            address = self.html.find('div', class_='mapaddress')\n",
    "            if address is not None:\n",
    "                location = address.text\n",
    "            else: location = None\n",
    "            return(location)\n",
    "\n",
    "        def get_lat_lon(self):\n",
    "            try:  \n",
    "                lat = self.html.find('div', id='map').get('data-latitude')\n",
    "                lon = self.html.find('div', id='map').get('data-longitude')\n",
    "                lat = float(lat)\n",
    "                lon = float(lon)\n",
    "            except:\n",
    "                lat=None\n",
    "                lon=None\n",
    "            return(lat, lon)\n",
    "\n",
    "        def get_attrgroup(self):\n",
    "            attrgroup = self.html.find('div', class_='mapAndAttrs')\n",
    "            attrlist = ['cats are OK - purrr', 'dogs are OK - wooof', 'air conditioning', \n",
    "            'furnished', 'w/d in unit', 'laundry on site', 'laundry in bldg', \n",
    "            'no laundry on site', 'no parking', 'street parking', 'off-street parking', \n",
    "            'detached garage']\n",
    "            if attrgroup is not None:\n",
    "                attrgroup.find_all('p', class_='attrgroup')[1]\n",
    "                attrgroup = set(attrgroup.text.split(\"\\n\"))\n",
    "                attrvals = []\n",
    "                for attr in attrlist:\n",
    "                    if attr in attrgroup:\n",
    "                        attrvals.append(1)\n",
    "                    else:\n",
    "                        attrvals.append(0)\n",
    "\n",
    "                return(attrvals)\n",
    "            else: return [0]*(len(attrlist))\n",
    "\n",
    "\n",
    "        def get_date(self):\n",
    "            return xml_getter(self.html.find('time'), before='title=\"', after = '\"')\n",
    "        \n",
    "        self.price = get_price(self)  \n",
    "        self.beds = get_beds(self)\n",
    "        self.sqft = get_sqft(self)\n",
    "        self.park = get_park(self)\n",
    "        self.baths = get_baths(self)\n",
    "        self.body = get_body(self)\n",
    "        self.address = get_address(self)\n",
    "        self.lat, self.lon = get_lat_lon(self)\n",
    "        self.attrgroup = get_attrgroup(self)\n",
    "        self.date = get_date(self)\n",
    "\n",
    "\n",
    "    def get_attributes(self):\n",
    "        self.parse()\n",
    "        attrs = [self.url, self.price, self.beds, self.sqft, self.park, self.baths, \n",
    "         self.body, self.address, self.lat, self.lon, self.date]+self.attrgroup\n",
    "        attrdict = {self.ID: attrs}\n",
    "        return attrdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gS64bk5Vwd0Q"
   },
   "source": [
    "# Generating page list:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "browser=start_browser()\n",
    "pages = get_pages(start_url = 'https://chicago.craigslist.org/search/apa',\n",
    "                  browser=browser,\n",
    "                  results=-1,\n",
    "                  cooldown=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4680"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listings = pd.Series(get_listings(pages, browser=browser))\n",
    "len(listings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "browser=start_browser()\n",
    "test = Listing(listings[0], browser)\n",
    "test.get_attributes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.0% scraped\n",
      "10.0% scraped\n",
      "15.0% scraped\n",
      "20.0% scraped\n",
      "25.0% scraped\n",
      "30.0% scraped\n",
      "35.0% scraped\n",
      "40.0% scraped\n",
      "45.0% scraped\n",
      "50.0% scraped\n",
      "55.0% scraped\n",
      "60.0% scraped\n",
      "65.0% scraped\n",
      "70.0% scraped\n",
      "75.0% scraped\n",
      "80.0% scraped\n",
      "85.0% scraped\n",
      "90.0% scraped\n",
      "95.0% scraped\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "cooldown=0\n",
    "results = {}\n",
    "browser=start_browser()\n",
    "for l in listings:\n",
    "    try:\n",
    "        entry = Listing(l, browser)\n",
    "    except:\n",
    "        try:\n",
    "            browser=start_browser()\n",
    "            entry = Listing(l, browser)\n",
    "        except:\n",
    "            entry=None\n",
    "    \n",
    "    if entry is not None:\n",
    "        results.update(entry.get_attributes())\n",
    "        percent = (100*len(results))/len(listings)\n",
    "        if percent%1==0:\n",
    "            print(str(percent)+\"% scraped\")\n",
    "            \n",
    "listingdf = pd.DataFrame.from_dict(results, orient='index')\n",
    "listingdf.columns = ['url', 'price', 'beds', 'sqft', 'parking', 'baths', 'descript', 'adress', 'lat', 'lon', 'date', \n",
    "                     'cats are OK - purrr', 'dogs are OK - wooof', 'air conditioning', \n",
    "              'furnished', 'w/d in unit', 'laundry on site', 'laundry in bldg', \n",
    "              'no laundry on site', 'no parking', 'street parking', 'off-street parking', \n",
    "              'detached garage']\n",
    "\n",
    "#Cleaning up listings that are improbably cheap or expensive\n",
    "listingdf = listingdf[listingdf['price']<10000]\n",
    "listingdf = listingdf[listingdf['price']>100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4544, 23)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "listingdf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "listingdf.to_csv(\"./CLScraped.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YGikUEIbeglt"
   },
   "source": [
    "# Analysis of Search Results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "listingdf = pd.read_csv(\"CLScraped.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "1PqljWfb716f"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'iteritems'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2260/4003003488.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcubehelix_palette\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrot\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m.25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFacetGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlistingdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"beds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"beds\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maspect\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpalette\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpal\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m g.map(sns.kdeplot, \"price\",\n\u001b[0m\u001b[1;32m      8\u001b[0m       \u001b[0mbw_adjust\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip_on\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m       fill=True, alpha=1, linewidth=1.5)\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/seaborn/axisgrid.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dropna\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    702\u001b[0m                 \u001b[0mplot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 703\u001b[0;31m             \u001b[0mplot_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mv\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mplot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miteritems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    704\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    705\u001b[0m             \u001b[0;31m# Some matplotlib functions don't handle pandas objects correctly\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   5987\u001b[0m         ):\n\u001b[1;32m   5988\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5989\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getattribute__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   5990\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5991\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'iteritems'"
     ]
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.set_theme(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "pal = sns.cubehelix_palette(10, rot=-.25, light=.7)\n",
    "g = sns.FacetGrid(listingdf, row=\"beds\", hue=\"beds\", aspect=15, height=.5, palette=pal)\n",
    "g.map(sns.kdeplot, \"price\",\n",
    "      bw_adjust=.5, clip_on=False,\n",
    "      fill=True, alpha=1, linewidth=1.5)\n",
    "\n",
    "g.map(sns.kdeplot, \"price\", clip_on=False, color=\"w\", lw=2, bw_adjust=.5)\n",
    "\n",
    "g.refline(y=0, linewidth=2, linestyle=\"-\", color=None, clip_on=False)\n",
    "\n",
    "def label(x, color, label):\n",
    "    ax = plt.gca()\n",
    "    ax.text(0, .2, label, fontweight=\"bold\", color=color,\n",
    "            ha=\"left\", va=\"center\", transform=ax.transAxes)\n",
    "\n",
    "g.map(label, \"price\")\n",
    "g.figure.subplots_adjust(hspace=-.25)\n",
    "g.set_titles(\"\")\n",
    "g.set(yticks=[], ylabel=\"\")\n",
    "g.despine(bottom=True, left=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "D3M5crC7O2w-"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0267*X+1894.0461\n",
      "r=0.1001\n",
      "p=0.0002\n"
     ]
    }
   ],
   "source": [
    "from scipy.stats import linregress\n",
    "model = listingdf[listingdf['sqft']<3000]\n",
    "'''\n",
    "f = sns.jointplot(x=model['sqft'], \n",
    "              y=model['price'], \n",
    "              #hue = model['beds'],\n",
    "              ratio=2,\n",
    "              kind='reg',\n",
    "              )\n",
    "'''\n",
    "slope, intercept, r, p, se = linregress(x=listingdf[listingdf['sqft']>0]['sqft'], y=listingdf[listingdf['sqft']>0]['price'])\n",
    "print(str(slope.round(4))+\"*X+\"+str(intercept.round(4))+\"\\nr=\"+str(r.round(4))+\"\\np=\"+str(p.round(4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "dUYJVgqyrEk-"
   },
   "outputs": [
    {
     "ename": "OptionError",
     "evalue": "\"No such keys(s): 'mode.use_inf_as_null'\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOptionError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2260/2672665624.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmulti_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmulti_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshade\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'R^2 Score: '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Coefs: \"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/seaborn/_decorators.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     44\u001b[0m             )\n\u001b[1;32m     45\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mkdeplot\u001b[0;34m(x, y, shade, vertical, kernel, bw, gridsize, cut, clip, legend, cumulative, shade_lowest, cbar, cbar_ax, cbar_kws, ax, weights, hue, palette, hue_order, hue_norm, multiple, common_norm, common_grid, levels, thresh, bw_method, bw_adjust, log_scale, color, fill, data, data2, warn_singular, **kwargs)\u001b[0m\n\u001b[1;32m   1768\u001b[0m             \u001b[0mplot_kws\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"color\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1769\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1770\u001b[0;31m         p.plot_univariate_density(\n\u001b[0m\u001b[1;32m   1771\u001b[0m             \u001b[0mmultiple\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmultiple\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1772\u001b[0m             \u001b[0mcommon_norm\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommon_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36mplot_univariate_density\u001b[0;34m(self, multiple, common_norm, common_grid, warn_singular, fill, legend, estimate_kws, **plot_kws)\u001b[0m\n\u001b[1;32m    926\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    927\u001b[0m         \u001b[0;31m# Do the computation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 928\u001b[0;31m         densities = self._compute_univariate_density(\n\u001b[0m\u001b[1;32m    929\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_variable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0mcommon_norm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/seaborn/distributions.py\u001b[0m in \u001b[0;36m_compute_univariate_density\u001b[0;34m(self, data_variable, common_norm, common_grid, estimate_kws, log_scale, warn_singular)\u001b[0m\n\u001b[1;32m    301\u001b[0m         \u001b[0mdensities\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 303\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0msub_vars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_data\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miter_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"hue\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfrom_comp_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    304\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    305\u001b[0m             \u001b[0;31m# Extract the data points from this sub set and remove nulls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36miter_data\u001b[0;34m(self, grouping_vars, reverse, from_comp_data)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    982\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfrom_comp_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 983\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcomp_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    984\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    985\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/seaborn/_core.py\u001b[0m in \u001b[0;36mcomp_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1052\u001b[0m                 \u001b[0;31m# Use the converter assigned to the axis to get a float representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m                 \u001b[0;31m# of the data, passing np.nan or pd.NA through (pd.NA becomes np.nan)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0;32mwith\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moption_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'mode.use_inf_as_null'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m                     \u001b[0morig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m                 \u001b[0mcomp_col\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    439\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mundo\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_get_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_get_option\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_option\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_single_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;31m# walk the nested dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.9/site-packages/pandas/_config/config.py\u001b[0m in \u001b[0;36m_get_single_key\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    119\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msilent\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    120\u001b[0m             \u001b[0m_warn_if_deprecated\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 121\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mOptionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"No such keys(s): {repr(pat)}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    123\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mOptionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Pattern matched multiple keys\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOptionError\u001b[0m: \"No such keys(s): 'mode.use_inf_as_null'\""
     ]
    }
   ],
   "source": [
    "from sklearn import linear_model\n",
    "y = model['price']\n",
    "x = model[['beds', 'sqft']]\n",
    "multi_model = linear_model.LinearRegression()\n",
    "multi_model.fit(x,y)\n",
    "sns.kdeplot(multi_model.predict(x)-y, shade=True)\n",
    "print('R^2 Score: '+str(round(multi_model.score(x,y), 4)))\n",
    "print(\"Coefs: \"+str(multi_model.coef_))\n",
    "print(\"Standard Error: \"+str(round((multi_model.predict(x)-y).std(),4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "mupKiqdXtBWw"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_2260/3520636423.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'price'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'sqft'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmulti_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinearRegression\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmulti_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkdeplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmulti_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshade\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "y = model['price']\n",
    "x = model[['sqft']]\n",
    "multi_model = linear_model.LinearRegression()\n",
    "multi_model.fit(x,y)\n",
    "sns.kdeplot(multi_model.predict(x)-y, shade=True)\n",
    "print('R^2 Score: '+str(multi_model.score(x,y).round(4)))\n",
    "print(\"Coefs: \"+str(multi_model.coef_))\n",
    "print(\"Standard Error: \"+str(round((multi_model.predict(x)-y).std(),4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p1TkrgTBvfjP"
   },
   "source": [
    "Number of bedrooms is not a significant factor over square-footage. Knowing the number of beds does not improve predictions of value, implying no meaningful relationship apart from communicating square-footage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8KUOmHkVaBMj"
   },
   "outputs": [],
   "source": [
    "model['rent']=model['price'].map(int)\n",
    "model['ppsf'] = model['price']/model['sqft']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YZg1Ds0SZkaF"
   },
   "outputs": [],
   "source": [
    "sns.histplot(model, x='ppsf', hue='beds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YvAd1qKswd0X"
   },
   "outputs": [],
   "source": [
    "#Fill in the blanks:\n",
    "def fetch_blank_listings(listingdf):\n",
    "  browser = start_browser()\n",
    "  browser.get(listingdf['url'][0])\n",
    "  tester = browser.page_source\n",
    "  if len(tester)>1000:\n",
    "    nans = listingdf[listingdf['html'].isna()]['url'].apply(lambda x: pull_html(x, cooldown=2))\n",
    "    return(nans)\n",
    "  else:\n",
    "    print(\"failed to fetch first listing\")\n",
    "    print(BeautifulSoup(browser.page_source))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rVeB3i68wcpN"
   },
   "outputs": [],
   "source": [
    "#Pull listings html:\n",
    "listingdf['html']=listingdf['url'][0:100].apply(lambda x: pull_html(x, cooldown=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fv9vpTpcxlWK"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W0jBzIAGwd0X"
   },
   "outputs": [],
   "source": [
    "\n",
    "parsed = listingdf.apply(lambda x: parse_listing_html(x['html']), axis='columns', result_type='expand')\n",
    "parsed.columns = ['baths', 'body', 'lat', 'lon', 'parking', 'dogs', 'cats', 'laundry']\n",
    "listingdf = listingdf.join(parsed)\n",
    "listingdf['Dpsf']=listingdf['rent']/listingdf['sqft']\n",
    "\n",
    "def clean(heading):\n",
    "    heading = heading.replace('QR Code Link to This Post\\n\\n\\n', \"\")\n",
    "    heading = heading.replace(\"\\n\", \"\")\n",
    "    heading = re.sub('[^0-9a-zA-Z]+', \" \", heading)\n",
    "    heading = heading.lower()\n",
    "    return(heading)\n",
    "\n",
    "    listingdf['heading'].map(clean)\n",
    "\n",
    "listingdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KOXAYQiB25Yu"
   },
   "outputs": [],
   "source": [
    "listingdf.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dceHopsu2rDN"
   },
   "outputs": [],
   "source": [
    "# importing all necessary modules\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "import matplotlib.pyplot as plt\n",
    " \n",
    "comment_words = ''\n",
    "stopwords = set(STOPWORDS)\n",
    " \n",
    "# iterate through the csv file\n",
    "for val in listingdf.dropna().body:\n",
    "     \n",
    "    # typecaste each val to string\n",
    "    val = str(val)\n",
    " \n",
    "    # split the value\n",
    "    tokens = val.split()\n",
    "     \n",
    "    # Converts each token into lowercase\n",
    "    for i in range(len(tokens)):\n",
    "        tokens[i] = tokens[i].lower()\n",
    "     \n",
    "    comment_words += \" \".join(tokens)+\" \"\n",
    " \n",
    "wordcloud = WordCloud(width = 800, height = 800,\n",
    "                background_color ='white',\n",
    "                stopwords = stopwords,\n",
    "                min_font_size = 10).generate(comment_words)\n",
    " \n",
    "# plot the WordCloud image                      \n",
    "plt.figure(figsize = (8, 8), facecolor = None)\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis(\"off\")\n",
    "plt.tight_layout(pad = 0)\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wJt3wwvjvco3"
   },
   "outputs": [],
   "source": [
    "text = \" \".join(clean(str(i)) for i in listingdf['body'].dropna())\n",
    "wordcloud = WordCloud().generate(text)\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis(\"off\")\n",
    "\n",
    "# lower max_font_size\n",
    "wordcloud = WordCloud(max_font_size=40).generate(text)\n",
    "plt.figure()\n",
    "plt.imshow(wordcloud, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tpZDxLwRhmcR"
   },
   "outputs": [],
   "source": [
    "#df=pd.read_csv('./CLScraped.csv')\n",
    "dummy = listingdf[['rent','sqft', 'beds', 'baths', 'parking', 'lat', 'lon', 'dogs', 'cats', 'laundry']].dropna()\n",
    "dummy['rent'] = dummy['rent'].apply(lambda x: (x-min(dummy['rent']))/(max(dummy['rent'])))\n",
    "dummy['beds']=dummy['beds']/max(dummy['beds'])\n",
    "dummy['dogs'].replace(\"None\", 0, inplace=True)\n",
    "dummy['dogs'].replace(\"dogs are OK - wooof\", 1, inplace=True)\n",
    "dummy['cats'].replace(\"None\", 0, inplace=True)\n",
    "dummy['cats'].replace('cats are OK - purrr', 1, inplace = True)\n",
    "dummy['laundry'].replace('laundry in bldg', 1, inplace=True)\n",
    "dummy[\"laundry\"].replace('laundry on site', 1, inplace=True)\n",
    "dummy['laundry'].replace(\"None\", 0, inplace=True)\n",
    "dummy[dummy['parking'].notnull()]['parking']=1\n",
    "dummy['parking'].fillna(0, inplace=True)\n",
    "dummy['sqft'].replace(0, None)\n",
    "dummy['lat'] = dummy['lat'].map(float)\n",
    "dummy['lon'] = dummy['lon'].map(float)\n",
    "#########delete this later\n",
    "dummy['baths']=dummy['baths'].apply(lambda x: float(x))\n",
    "#########\n",
    "\n",
    "dummy['baths']=dummy['baths']/max(dummy['baths'])\n",
    "\n",
    "dummy = dummy.drop(columns=['sqft', 'parking'])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Copy of CLScraper.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
